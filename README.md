# VLM_DEMO ‚Äî SmolVLM demo

–ù–µ–±–æ–ª—å—à–æ–π –¥–µ–º–æ-–ø—Ä–æ–µ–∫—Ç: FastAPI backend + Streamlit frontend, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å SmolVLM-–ø–æ–¥–æ–±–Ω–æ–π –º–æ–¥–µ–ª–∏ (–º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ `models/`).

**–ö–ª—é—á–µ–≤—ã–µ –ø–∞–ø–∫–∏**
- `backend/` ‚Äî –∫–æ–¥ FastAPI, Dockerfile –¥–ª—è –±—ç–∫–µ–Ω–¥–∞, —Ç–æ—á–∫–∞ –∑–∞–ø—É—Å–∫–∞: `backend/app/main.py`.
- `frontend/` ‚Äî Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (`frontend/app.py`) –∏ Dockerfile –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞.
- `models/` ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏ (–≤–∫–ª—é—á–∞—è `model.safetensors` –∏ –∫–æ–Ω—Ñ–∏–≥–∏).

**–ö—Ä–∞—Ç–∫–æ**
- –ó–∞–ø—É—Å–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω —á–µ—Ä–µ–∑ Docker Compose: —Å–µ—Ä–≤–∏—Å—ã `backend` –∏ `frontend` —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –∏–∑ `backend/Dockerfile` –∏ `frontend/Dockerfile`.

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (–ª–æ–∫–∞–ª—å–Ω–æ / –¥–ª—è —Å–±–æ—Ä–∫–∏ –æ–±—Ä–∞–∑–æ–≤)**
- Docker & Docker Compose (–≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö: `docker compose` CLI).
- –î–ª—è GPU-—Ä–µ–∂–∏–º–∞: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA –Ω–∞ —Ö–æ—Å—Ç–µ –∏ `nvidia-container-toolkit` (—Å–º. —Ä–∞–∑–¥–µ–ª "GPU").

**–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Docker Compose)**

1) –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ):

```bash
docker compose up --build -d
```

2) –û—Ç–∫—Ä—ã—Ç—å —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥: http://localhost:8501

3) –õ–æ–≥–∏ –±—ç–∫–µ–Ω–¥–∞:

```bash
docker compose logs -f backend
```

**–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è**
- –§–∞–π–ª `.env` (–≤ –∫–æ—Ä–Ω–µ) –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–∞–¥–∞—é—Ç—Å—è –≤ `docker-compose.yml`):

- `DEVICE` ‚Äî `cpu` –∏–ª–∏ `gpu` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `cpu`).
- `BACKEND_PORT` / `BACKEND_INTERNAL_PORT` ‚Äî –ø–æ—Ä—Ç —Ö–æ—Å—Ç–∞ –∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 8000).
- `FRONTEND_PORT` ‚Äî –ø–æ—Ä—Ç –¥–ª—è Streamlit (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 8501).
- `VQA_MODEL_ID` ‚Äî id/–ø—É—Ç—å –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `HuggingFaceTB/SmolVLM2-256M-Video-Instruct`).
- `HF_HOME` ‚Äî –∫–µ—à Hugging Face (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `/root/.cache/huggingface`).
- `MODELS_DIR` ‚Äî –º–æ–Ω—Ç–∏—Ä—É–µ–º–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `/models`).
- `UPLOADS_DIR` ‚Äî –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `/app/uploads`).

–ò–∑–º–µ–Ω–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–∂–Ω–æ –≤ —Ñ–∞–π–ª–µ `.env` –∏–ª–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º `docker compose` –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.

**–†–∞–±–æ—Ç–∞ —Å –º–æ–¥–µ–ª—è–º–∏**
- –ü–∞–ø–∫–∞ `models/` –º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∫–∞–∫ `/models`. –ü–æ–º–µ—Å—Ç–∏—Ç–µ —Å—é–¥–∞ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—É—é –º–æ–¥–µ–ª—å.

**GPU: –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω rebuild –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞?**

- –ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: –Ω–µ—Ç, –Ω–µ –≤—Å–µ–≥–¥–∞. –ï—Å–ª–∏ –æ–±—Ä–∞–∑ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç GPU-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –±–∏–Ω–∞—Ä–Ω–∏–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA) –∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ GPU, —Ç–æ –º–µ–Ω—è—Ç—å `DEVICE=cpu` ‚Üí `DEVICE=gpu` –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–æ ‚Äî –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞—Ç—å –æ–±—Ä–∞–∑ –Ω–µ –Ω–∞–¥–æ.

- –ù–û: —á–∞—Å—Ç–æ –æ–±—Ä–∞–∑—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç CPU-–≤–µ—Ä—Å–∏—é PyTorch (–∏–ª–∏ –≤–æ–æ–±—â–µ CPU-only –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏). –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ GPU –Ω—É–∂–Ω–æ –ª–∏–±–æ:
  - –ø–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑, —É—Å—Ç–∞–Ω–æ–≤–∏–≤ GPU-–∫–æ–ª–µ—Å–∞ PyTorch / CUDA-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –∏–ª–∏
  - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –æ–±—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç CUDA-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ / GPU-–≤–µ—Ä—Å–∏—é PyTorch.

- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π:
  1. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –±–µ–∑ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏: –≤ `.env` —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `DEVICE=gpu` –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ–º, –Ω–æ –±–µ–∑ —Å–±–æ—Ä–∫–∏ –æ–±—Ä–∞–∑–æ–≤:

```bash
# –æ–±–Ω–æ–≤–∏–ª–∏ .env
docker compose up -d --no-build --force-recreate backend
```

  2. –ï—Å–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π –∏–º–ø–æ—Ä—Ç–∞/–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ CUDA (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—à–∏–±–∫–∏ –∏–º–ø–æ—Ä—Ç–∞ `torch` —Å CUDA), –∑–Ω–∞—á–∏—Ç –≤ –æ–±—Ä–∞–∑–µ –Ω–µ—Ç GPU-–±–∏–±–ª–∏–æ—Ç–µ–∫ ‚Äî –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑ —Å GPU-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ –ø–∞–∫–µ—Ç–∞–º–∏.

  3. –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è):

```bash
docker compose build --no-cache backend
docker compose up -d
```

  4. –î–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ GPU —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–∞ —Ö–æ—Å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA –∏ `nvidia-container-toolkit`. –ó–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ñ–ª–∞–≥–æ–º `--gpus` –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ `device_requests` –≤ `docker-compose.yml`.

–ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ –≤—Ä—É—á–Ω—É—é —Å `docker run`:

```bash
docker run --gpus all -e DEVICE=gpu \
  -v $(pwd)/models:/models \
  -p 8000:8000 \
  --name smolvlm-backend your-image-name
```

–ü—Ä–∏–º–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –¥–ª—è `docker-compose.yml` (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π `device_requests`):

```yaml
services:
  backend:
    # ...
    device_requests:
      - driver: nvidia
        count: all
        capabilities: [gpu]
```

–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –ø–æ–ª–µ `device_requests` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–µ –≤–æ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö Compose; –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `docker run --gpus`.

**–ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ (–±–µ–∑ Docker)**
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Python 3.9, —Å–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ `requirements_b.txt` (–¥–ª—è backend) –∏ `requirements_f.txt` (–¥–ª—è frontend).

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements_b.txt
uvicorn backend.app.main:app --host 0.0.0.0 --port 8000

# –∏ –≤ –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
pip install -r requirements_f.txt
streamlit run frontend/app.py --server.port 8501 --server.address 0.0.0.0
```

**–ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã**
- –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±—ç–∫–µ–Ω–¥ –±–µ–∑ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ (–ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ `.env`):

```bash
docker compose up -d --no-build --force-recreate backend
```

- –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫:

```bash
docker compose up --build -d
```

**–û—Ç–ª–∞–¥–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å CUDA / PyTorch**
- –ï—Å–ª–∏ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –≤—ã –≤–∏–¥–∏—Ç–µ –æ—à–∏–±–∫–∏ –≤—Ä–æ–¥–µ "CUDA not available" –∏–ª–∏ "libcuda.so not found", –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:
  - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ª–∏ NVIDIA-–¥—Ä–∞–π–≤–µ—Ä—ã –Ω–∞ —Ö–æ—Å—Ç–µ;
  - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ `nvidia-container-toolkit`;
  - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ª–∏ GPU-–≤–µ—Ä—Å–∏—è PyTorch (–≤ –æ–±—Ä–∞–∑–µ).

**–ö–æ–Ω—Ç–∞–∫—Ç—ã / –¥–∞–ª–µ–µ**
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –º–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø—Ä–∏–º–µ—Ä `Dockerfile` –∏ `requirements_b.txt`, —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–æ–¥ CUDA (—É–∫–∞–∑–∞—Ç—å –∂–µ–ª–∞–µ–º—É—é –≤–µ—Ä—Å–∏—é CUDA), –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ `docker-compose.override.yml` –¥–ª—è GPU.

---

–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ, –¥–æ–±–∞–≤–ª—é –ø—Ä–∏–º–µ—Ä `docker-compose.override.yml` –¥–ª—è GPU –∏/–∏–ª–∏ –∞–¥–∞–ø—Ç–∏—Ä—É—é `backend/Dockerfile` –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é CUDA. –ù–∞–ø–∏—à–∏—Ç–µ, –∫–∞–∫—É—é –≤–µ—Ä—Å–∏—é CUDA/torch –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏—Ç–µ "–∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–æ–¥–æ–±—Ä–∞—Ç—å").
# üìù BLIP Image Captioning Application

A full-stack web application for generating image captions using the BLIP model from Salesforce. This project provides both a REST API backend and an interactive web interface for automated image description generation.

## Running:

For building do:

```bash
docker compose up --build -d
```

For running tests do:
```bash
sh run_tests.sh
```# VLM_DEMO
